<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CV上分思路和技巧</title>
    <url>/2023/08/11/CV%E4%B8%8A%E5%88%86%E6%80%9D%E8%B7%AF%E5%92%8C%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<h1 id="CV上分思路和技巧"><a href="#CV上分思路和技巧" class="headerlink" title="CV上分思路和技巧"></a>CV上分思路和技巧</h1><ul>
<li><p>修改模型</p>
</li>
<li><p>修改数据增广方法</p>
<ul>
<li>主要分为两类，不改变图片标签的和改变图片标签的</li>
<li>如果使用改变图片标签的数据增广，那么模型需要更多的epoch训练，可能两倍以上</li>
<li>mixup的原理其实就是两个图片的pixel以及标签做加权求和</li>
<li>一般来说，val和test的数据增强可以比train稍微弱一点</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/CV上分思路和技巧/Snipaste_2023-08-11_11-51-34.png" alt="Snipaste_2023-08-11_11-51-34"></p>
<ul>
<li>修改学习过程的超参数<ul>
<li>优化器</li>
<li>学习率，比如使用余弦退火的lr_scheduler</li>
</ul>
</li>
<li>使用模型集成方法<ul>
<li>Test Time Augmentation<ul>
<li>测试阶段，对样本进行数据增强，然后将未增强样本的结果和增强样本的结果求平均</li>
</ul>
</li>
<li>Snapshot Ensemble/ Stochastic Weight Averaging<ul>
<li>在训练过程中保存多个中间权重，测试时使用这些权重一一进行预测，结果求平均</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/CV上分思路和技巧/Snipaste_2023-08-11_13-56-55.png" alt=""></p>
<ul>
<li>对测试集使用伪标签，合并训练</li>
</ul>
<p><img src="/images/blogs/CV上分思路和技巧/Snipaste_2023-08-11_14-02-08.png" alt=""></p>
<ul>
<li>使用交叉验证<ul>
<li>可以用来选择超参数</li>
<li>也可以用交叉验证训练出的多个模型进行模型集成</li>
<li>代码如下所示，即从生成dataloader开始，到训练并保存模型，在这部分代码外面套一个循环，循环次数就是K折交叉验证</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/CV上分思路和技巧/Snipaste_2023-08-11_14-04-50.png" alt=""></p>
]]></content>
      <categories>
        <category>比赛</category>
      </categories>
      <tags>
        <tag>炼丹</tag>
        <tag>比赛</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN: Generative Adversarial Nets</title>
    <url>/2023/08/10/GAN-Generative-Adversarial-Nets/</url>
    <content><![CDATA[<h1 id="GAN-Generative-Adversarial-Nets"><a href="#GAN-Generative-Adversarial-Nets" class="headerlink" title="GAN: Generative Adversarial Nets"></a>GAN: Generative Adversarial Nets</h1><h2 id="1-标题及作者"><a href="#1-标题及作者" class="headerlink" title="1. 标题及作者"></a>1. 标题及作者</h2><ul>
<li>模型的两大类：判别模型，生成模型<ul>
<li>判别模型：预测、分类。</li>
<li>生成模型：世界是通过采样不同的分布形成的，如果你要生成某个数据，就是要在它的分布上进行采样。所以生成模型的目标就是拟合到某种数据的分布。</li>
</ul>
</li>
</ul>
<h2 id="2-摘要"><a href="#2-摘要" class="headerlink" title="2. 摘要"></a>2. 摘要</h2><p>GAN是通过一个adversial process来预测生成模型。GAN会同时训练两个模型$G$和$D$，生成模型$G$的目标是捕捉到真实的数据分布，判别模型$D$的目标是分辨一个数据是否来自真实的数据分布。训练过程中，$D$的目标是提高分类的准确率，$G$的目标是最大化$D$的错误率。最终使得$G$找到真实的数据分布，即$G$捕捉的数据分布与真实数据分布完全重合，此时$D$对每个输入的预测都为0.5（等于随机预测）。用MLP来构建$G$和$D$，使用反向传播和梯度下降来训练这两个模型，而不使用传统的生成模型算法（如马尔科夫链）。</p>
<h2 id="3-引言"><a href="#3-引言" class="headerlink" title="3. 引言"></a>3. 引言</h2><h3 id="3-1-Issue"><a href="#3-1-Issue" class="headerlink" title="3.1 Issue"></a>3.1 Issue</h3><ul>
<li>Discriminative model已经取得了很大进展</li>
<li>但是Generative model还没有取得同样的进展，因为传统方法是要对未知的数据分布进行近似，然后计算似然函数。但是这种近似给计算带来了很多困难。</li>
<li>不使用似然函数了，使用一个对抗策略的框架</li>
</ul>
<h3 id="3-2-Framework"><a href="#3-2-Framework" class="headerlink" title="3.2 Framework"></a>3.2 Framework</h3><ul>
<li><p>framework basisi就是双人对抗，同时训练两个模型，一个负责捕捉真是数据分布，一个负责分辨数据是否来自真实分布，直到生成模型找到真实分布。</p>
</li>
<li><p>generative model：是一个MLP，输入是随机噪音（通常属于高斯分布），这个MLP可以将产生噪音的分布映射到我们想要的任何数据的分布上去</p>
</li>
<li>discriminative model：也是一个MLP，输入一个数据，输出一个scalar，用于判别输入的数据是否来自真实数据分布</li>
<li>以上这种G和D都是MLP的special case，称为adversarial nets，在adversarial nets下，可以利用误差的反向传播来训练模型，不需要对数据做复杂采样或对分布做复杂的近似。</li>
</ul>
<h2 id="4-相关工作"><a href="#4-相关工作" class="headerlink" title="4. 相关工作"></a>4. 相关工作</h2><ul>
<li><p>曾经主流的方法是显式地构建目标数据的概率分布，概率分布中提供一些可学习的参数，然后根据数据样本通过最大化其对数似然函数来学习参数。例如，波兹曼机。</p>
<ul>
<li>问题：当数据维度很高时，概率分布难以用最大似然函数来计算，因为计算非常困难；另外，真实数据的分布有时很难构造</li>
</ul>
</li>
<li><p>因此催生了另一类方法：generative machines，不再显式地构造概率分布，而是利用模型去近似概率分布。例如，VAE，NCE。</p>
<ul>
<li>问题：不能知道数据分布的显式表达，但是可以利用反向传播、梯度下降来更新参数，使计算非常简单。</li>
</ul>
</li>
</ul>
<h2 id="5-模型"><a href="#5-模型" class="headerlink" title="5. 模型"></a>5. 模型</h2><ul>
<li>generator $G$: 为了让生成器学习数据$x$的分布（生成器学到的分布用$p_g$表示），我们在输入噪音$z$上定义一个先验分布$p_z(z)$（一般是高斯分布），然后通过一个函数$G(z;\theta_g)$表示从先验分布到目标分布的映射，其中$G$是一个可微分函数，GAN中用MLP构建，其参数为$\theta_g$<ul>
<li>论文中是用scalar来表示$z$和$x$，在实际中，比如生成4k图像时，图像有八百万个像素，每个像素表示为一个随机变量，每个变量都服从一个分布，整个图像服从一个联合分布；如果隐向量$z$设定为100维（超参数，根据生成数据的复杂度而选择，两者不需要相等），那么就需要初始化100个随机变量的分布；最终生成器就是一个初始输入为100维，最终输出为八百万维的MLP。</li>
</ul>
</li>
<li>discriminator $D$: 定义另一个MLP模型$D(x;\theta_d)$，输入为数据$x$，最终输出一个scalar，这个scalar表示$x$来自真实数据分布的概率。</li>
<li>loss function: <ul>
<li>同时训练两个模型，对$D$，我们希望它能尽可能地分辨正确$x$是否来自真是数据分布；对$G$，我们希望它生成的数据能尽可能地被$D$判定为真实数据。</li>
<li>损失函数：<ul>
<li>先看内部对$D$的max：当$D$达到理想效果时，$D(x)$为1，函数的第一部分为0，$D(G(z))$为0，函数的第二部分为0，求和为0；如果不是理想效果，则函数结果为负。因此为了让$D$达到理想效果，应该让函数尽可能大</li>
<li>然后看外部对$G$的min：与$G$有关的只有函数的后一项，当$G$达到理想效果时，$D(G(z))$为1，则函数的后一项为负无穷，函数求和为负无穷。因此为了让$G$达到理想效果，应该让函数尽可能小</li>
<li>损失函数公式如下所示：</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GAN-Generative-Adversarial-Nets/Snipaste_2023-08-10_21-24-06.png" alt=""></p>
<ul>
<li>学习过程：<ul>
<li>如图所示，初始时$D$和$G$的效果都有较大偏差。随后在每次迭代中，$D$先优化，学到真实数据和$G$生成数据的区别；然后$G$优化数据分布，减小$D$的分类准确率。经过多次迭代后，$G$生成数据的分布和真实数据分布完全重合。</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GAN-Generative-Adversarial-Nets/Snipaste_2023-08-10_21-38-27.png" alt=""></p>
<ul>
<li>算法描述：</li>
</ul>
<p><img src="/images/blogs/GAN-Generative-Adversarial-Nets/Snipaste_2023-08-10_21-39-19.png" alt=""></p>
<h2 id="6-优缺点"><a href="#6-优缺点" class="headerlink" title="6. 优缺点"></a>6. 优缺点</h2><ul>
<li><p>GAN不需要显式地表示数据分布，因而可以利用网络模型拟合非常复杂的数据，计算上也方便很多</p>
</li>
<li><p>GAN的训练非常不稳定，因为它需要每次迭代中$G$和$D$的能力相当，不能某个模型的能力过强，否则另一个模型无法收敛；但要求每次迭代时$D$要在当前的$G$模型下分辨能力有优化，否则$G$也无法学到很好的分布；另外，GAN的训练不需要推理，$D$和$G$两个模型是否都收敛了比较难判断。</p>
</li>
<li>GAN是半监督学习的灵感之一，因为它的数据生成是无监督的，即数据不需要标记；但损失函数是有监督的，唯一的监督信息是数据来源于真实数据分布还是生成器，而这个监督信息是训练时自己定义的。</li>
</ul>
]]></content>
      <categories>
        <category>沐神开组会</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>李沐</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN: Graph Neural Networks</title>
    <url>/2023/08/10/GNN-Graph-Neural-Networks/</url>
    <content><![CDATA[<h1 id="GNN-Graph-Neural-Networks"><a href="#GNN-Graph-Neural-Networks" class="headerlink" title="GNN: Graph Neural Networks"></a>GNN: Graph Neural Networks</h1><blockquote>
<p>《An gentle introduction to graph neural networks》</p>
<p>——图结构数据如何表示为tensor；GNN如何处理图数据；GNN网络是由什么模块组成</p>
</blockquote>
<h2 id="1-Introduction-to-Graphs"><a href="#1-Introduction-to-Graphs" class="headerlink" title="1. Introduction to Graphs"></a>1. Introduction to Graphs</h2><ul>
<li>A graph represents the relations(edges) between a collection of entities(nodes). 一般来说，一个图可以表示为V、E和U，如下所示：</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230719111108017.png" alt="image-20230719111108017"></p>
<p>——其中，attributes表示每个节点、每条边、整个图所表示的<strong>信息</strong>。为了进一步定量地表示这些信息，我们可以用（不同维度的）向量来表示每个节点、每条边、整个图所表示的<strong>信息</strong>。</p>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230719111437197.png" alt="image-20230719111437197"></p>
<p>——其中，左上角的节点的信息用一个长度为6的向量表示，高矮表示特征值的大小。重点在于，这些向量能否很好地定量表示图的信息，<strong>GNN要如何学习到这些向量</strong>。</p>
<ul>
<li>根据edge是否有方向，可以将graph分为directed graph和undirected graph：</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230719112047988.png" alt="image-20230719112047988"></p>
<h2 id="2-Represent-Data-as-Graphs"><a href="#2-Represent-Data-as-Graphs" class="headerlink" title="2. Represent Data as Graphs"></a>2. Represent Data as Graphs</h2><h3 id="Images-as-Graphs"><a href="#Images-as-Graphs" class="headerlink" title="Images as Graphs"></a>Images as Graphs</h3><ul>
<li>Typically，我们将images表示为带通道的矩阵，即三维tensor(eg. 224*224*3)</li>
<li>将images表示为整齐的graph：<ul>
<li>每个pixel看作一个节点</li>
<li>每个pixel的RGB值形成一个三维向量，作为该节点的向量表示</li>
<li>每个pixel与邻接pixel之间形成边(<strong>undirected</strong>)。这样每个non-border pixel都有8个邻居节点。</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230719114043583.png" alt="image-20230719114043583"></p>
<ul>
<li>image的三种表示，依次为：图片像素值、邻接矩阵（大小为nodes*nodes）、graph</li>
</ul>
<h3 id="Texts-as-Graphs"><a href="#Texts-as-Graphs" class="headerlink" title="Texts as Graphs"></a>Texts as Graphs</h3><ul>
<li><p>Typically，我们将一段文本划分为token，将每个token映射为索引，然后将这段文本表示为索引序列。</p>
</li>
<li><p>将text表示为graph：</p>
<ul>
<li>每个token作为一个节点，词向量可以作为节点向量</li>
<li>text sequence是一个单向的序列，因此其中的边是有向边；每个非结尾的token应该有一条有向边指向与其相邻的下一个token</li>
</ul>
</li>
</ul>
<h3 id="Graph-valued-Data-in-the-Wild"><a href="#Graph-valued-Data-in-the-Wild" class="headerlink" title="Graph-valued Data in the Wild"></a>Graph-valued Data in the Wild</h3><ul>
<li>text和image通常不会表示成graph，因为text和image本身已经是非常规则的数据了，表示成graph时，其邻接矩阵会非常稀疏，比如image的邻接矩阵是带状，而text的邻接矩阵是对角线</li>
<li>而有些数据，很难用除了graph以外的数据形式来表示<ul>
<li>分子图：每个原子作为一个节点，原子间的化学键作为边</li>
<li>社交网络图：每个人作为一个节点，如果两个人之间有交互行为，则在这两个点之间构建一条边</li>
<li>引用图：每篇论文作为一个节点，论文A引用论文B则有一条A到B的有向边</li>
</ul>
</li>
</ul>
<h2 id="3-Different-Tasks-on-Graphs"><a href="#3-Different-Tasks-on-Graphs" class="headerlink" title="3. Different Tasks on Graphs"></a>3. Different Tasks on Graphs</h2><h3 id="Graph-level-task"><a href="#Graph-level-task" class="headerlink" title="Graph-level task"></a>Graph-level task</h3><ul>
<li>在图级别任务中，我们的目标是<strong>预测整个图的属性</strong>。例如，对于以graph表示的分子，我们可能想要预测分子的气味，或者它是否会结合到与疾病相关的受体上。(classification)</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230720113247688.png" alt="image-20230720113247688"></p>
<h3 id="Node-level-task"><a href="#Node-level-task" class="headerlink" title="Node-level task"></a>Node-level task</h3><ul>
<li>节点级任务关注于<strong>预测图中每个节点的身份或角色</strong>。</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230720113727209.png" alt="image-20230720113727209"></p>
<ul>
<li>类比图像，节点级预测问题类似于图像分割，我们试图标记图像中每个像素的作用。对于文本，类似的任务是预测句子中每个单词的词性。(细粒度的classfication)</li>
</ul>
<h3 id="Edge-level-task"><a href="#Edge-level-task" class="headerlink" title="Edge-level task"></a>Edge-level task</h3><ul>
<li>边级别任务关注于<strong>预测节点之间是否有边存在，以及边的属性如何</strong>，即预测nodes之间是否存在关系，存在哪种关系。</li>
<li>一个具体的例子是图片场景理解，要判断节点之间的关系，可以先给定包含所有结点的全连接图，然后根据模型对边的预测值来修剪边，得到稀疏的图：</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230720114134124.png" alt="image-20230720114134124"></p>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230720114214671.png" alt="image-20230720114214671"></p>
<h2 id="4-Represent-Graphs-as-Tensors"><a href="#4-Represent-Graphs-as-Tensors" class="headerlink" title="4. Represent Graphs as Tensors"></a>4. Represent Graphs as Tensors</h2><blockquote>
<p>So, how do we go about solving these different graph tasks with neural networks? The first step is to think about how we will represent graphs to be compatible with neural networks.</p>
</blockquote>
<ul>
<li>Graphs have up to four types of information: <strong>nodes, edges, global-context and connectivity.</strong></li>
<li>The first three are relatively straightforward: for example, with nodes we can form a node feature matrix $N$ by assigning each node an index $i$ and storing the feature for $node_i$ in $N$.</li>
<li><p><strong>Representing a graph’s connectivity</strong> is more complicated.</p>
<ul>
<li><p>use an adjacency matrix：</p>
<ul>
<li>easily tensorisable</li>
<li>leads to very sparse adjacency matrices, which are space-inefficient</li>
<li>not permutation invariant（many adjacency matrices that can encode the same connectivity）</li>
</ul>
</li>
<li><p>use an adjacency lists：</p>
<ul>
<li>avoid computation and storage on the disconnected parts of the graph</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230725220911217.png" alt="image-20230725220911217"></p>
<h2 id="5-Graph-Neural-Network"><a href="#5-Graph-Neural-Network" class="headerlink" title="5. Graph Neural Network"></a>5. Graph Neural Network</h2><blockquote>
<p>Now we’ve represented graph as tensors, how we use neural network to deal with these tensors?</p>
</blockquote>
<ul>
<li><strong>A GNN is an optimizable transformation on all attributes of the graph (nodes, edges, global-context) that preserves graph symmetries.</strong> 即，GNN就是对属性做变换，但不改变图的结构。</li>
<li>GNNs adopt <strong>a “graph-in, graph-out” architecture</strong> meaning that these model types accept a graph as input, with information loaded into its nodes, edges and global-context, and progressively transform these embeddings, without changing the connectivity of the input graph.</li>
</ul>
<h3 id="The-simplest-GNN"><a href="#The-simplest-GNN" class="headerlink" title="The simplest GNN"></a>The simplest GNN</h3><ul>
<li>The simplest GNN architecture, one where we learn new embeddings for all graph attributes (nodes, edges, global), but where we do not yet use the connectivity of the graph.</li>
<li>This GNN uses <strong>a separate multilayer perceptron (MLP) on each component of a graph</strong>; we call this a GNN layer. Layer $N$ of this GNN includes $f<em>{U_n}, f</em>{V<em>n}, f</em>{E_n}$. 即为了不改变connectivity，我们对node, edge和global-context分别构造一个MLP以对embedding进行转换，这三个MLP构成GNN的一个layer。</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726094537247.png" alt="image-20230726094537247"></p>
<ul>
<li>We can <strong>stack these GNN layers</strong> together to build a deeper GNN. (需要pooling层，否则MLP堆叠没有意义)</li>
<li>Because a GNN does <strong>not update the connectivity of the input graph</strong>, we can describe the output graph of a GNN with the same adjacency list and the same number of feature vectors as the input graph.</li>
</ul>
<h3 id="GNN-Predictions-using-Pooling-Information"><a href="#GNN-Predictions-using-Pooling-Information" class="headerlink" title="GNN Predictions using Pooling Information"></a>GNN Predictions using Pooling Information</h3><blockquote>
<p>如何用output graph来完成一个nodel-level的binary classification任务呢？</p>
</blockquote>
<ul>
<li>直观的，因为graph中包含了每个node的embedding，我们可以用final layer输出的graph信息，将每个node embedding投入一个output dimension为2的全连接层，然后进行softmax，获得分类结果：</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726095501604.png" alt="image-20230726095501604"></p>
<ul>
<li>但如果我们没有node embeddings（或出于某种原因不能使用），只能用相关的其他信息，比如edges embeddings来解决node-level binary classification任务，then we need a way to <strong>collect information from edges and give them to nodes for prediction</strong>. We can do this by <strong><em>pooling</em></strong>. 无论缺少哪类信息，都可以利用pool操作来汇聚其他类的attribute，弥补缺失的信息</li>
<li>Pooling proceeds in two steps: <strong><em>gather</em></strong> and <strong><em>aggregated</em></strong>.</li>
<li>这里对每个结点gather它的邻接边，以及全局信息，然后使用求和sum进行aggregation<ul>
<li>假设各类attribute的维度相同，如果不相同就需要进行projection</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726100842458.png" alt="image-20230726100842458"></p>
<h4 id="Different-type-of-pooling"><a href="#Different-type-of-pooling" class="headerlink" title="Different type of pooling"></a>Different type of pooling</h4><ul>
<li>Pool edge embeddings into nodes to make nodel-level predictions, denoted as $\rho<em>{E_n\rightarrow V</em>{n}}$:<ul>
<li>在获取了node embedding后，和前文一样，将其投入一个全连接层进行prediction</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726101108039.png" alt="image-20230726101108039"></p>
<ul>
<li>Pool node embeddings into edges to make edge-level predictions, denoted as $\rho<em>{V_n\rightarrow E</em>{n}}$:<ul>
<li>每条边连接两个顶点，将这两个node embedding和global-context相加，得到edge embedding</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726101323227.png" alt="image-20230726101323227"></p>
<ul>
<li>Pool node/edge embeddings into global context to make global predictions, denoted as $\rho<em>{V_n\rightarrow U</em>{n}}$：<ul>
<li>如果只有node embedding，可以将所有的node embedding相加求和，作为global-context；然后投入一个全连接层，进行global-level prediction</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726104148023.png" alt="image-20230726104148023"></p>
<h4 id="End-to-end-Simplest-GNN："><a href="#End-to-end-Simplest-GNN：" class="headerlink" title="End-to-end Simplest GNN："></a>End-to-end Simplest GNN：</h4><p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726104508078.png" alt="image-20230726104508078"></p>
<ul>
<li><p>Note that in this simplest GNN formulation, we’re not using the connectivity of the graph at all inside the GNN layer. We only use connectivity when pooling information for prediction.</p>
</li>
<li><p>如何在GNN中构建使用connectivity信息的模块？使用Pool或者message pass。两者的区别在于，pool是不同的attributes，相邻的entity之间进行信息传递；message pass是相同的attribute，相邻的entity之间进行信息传递。how to apply pool or message pass within GNN layer ❤</p>
</li>
</ul>
<h3 id="Passing-messages-between-parts-of-the-graph"><a href="#Passing-messages-between-parts-of-the-graph" class="headerlink" title="Passing messages between parts of the graph"></a>Passing messages between parts of the graph</h3><blockquote>
<p>在simplest GNN中，每个Layer里的MLP是独立地处理不同type的attribute，没有将图的信息融合进output graph中，这样无法充分利用图的信息。</p>
</blockquote>
<ul>
<li><em>Message passing</em> means neighboring nodes or edges exchange information and influence each other’s updated embeddings.</li>
<li>Message passing works in three steps: <strong><em>gather</em></strong>($g$), <strong><em>aggregate</em></strong> and <strong><em>update</em></strong>. This sequence of operations, when applied once, is the simplest type of <strong>message-passing GNN layer</strong>.</li>
</ul>
<h4 id="Message-passing-between-nodes"><a href="#Message-passing-between-nodes" class="headerlink" title="Message passing between nodes"></a>Message passing between nodes</h4><ul>
<li>在simplest GNN中，对node embedding进行更新时，我们直接将一个node embedding投入对应的MLP；</li>
<li>在信息传递层里，对一个node进行更新，需要收集它所有的邻接节点（gather），与它自身的embedding相加求和（aggregate），然后再投入MLP（update），这样就是一个node-message-passing GNN Layer</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726110637076.png" alt="image-20230726110637076"></p>
<h4 id="Graph-Convolutional-Layer"><a href="#Graph-Convolutional-Layer" class="headerlink" title="Graph Convolutional Layer"></a>Graph Convolutional Layer</h4><ul>
<li><p>This is reminiscent of standard convolution: in essence, <strong><em>message passing and convolution are operations to aggregate and process the information of an element’s neighbors in order to update the element’s value</em></strong>. In graphs, the element is a node, and in images, the element is a pixel. However, the number of neighboring nodes in a graph can be variable, unlike in an image where each pixel has a set number of neighboring elements.</p>
</li>
<li><p>By <strong><em>stacking message passing GNN layers</em></strong> together, <strong><em>a node can eventually incorporate information from across the entire graph</em></strong>: after three layers, a node has information about the nodes three steps away from it. 就像感受野一样，最终可以获得全局图片的信息。</p>
</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230726111530116.png" alt="image-20230726111530116"></p>
<h4 id="Message-Passing-Layer"><a href="#Message-Passing-Layer" class="headerlink" title="Message Passing Layer"></a>Message Passing Layer</h4><ul>
<li>我们也可以在节点和边之间进行信息传递</li>
<li>如下所示，在一个信息传递层里，我们先进行节点到边的信息汇聚，再进行边到节点的信息汇聚，然后对各类attribute进行更新<ul>
<li>当节点和边的dimension不同时，可以先进行Projection再相加，也可以在更新前将它们concatenate起来</li>
<li>如果维度相同，就可以直接相加</li>
</ul>
</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230810152155216.png" alt="image-20230810152155216"></p>
<ul>
<li>先做点到边的汇聚还是先做边到点的汇聚，会导致不同的结果。具体采用什么顺序要看网络的设计。</li>
</ul>
<h3 id="Global-Rpresentations"><a href="#Global-Rpresentations" class="headerlink" title="Global Rpresentations"></a>Global Rpresentations</h3><blockquote>
<p>There is one flaw with the networks we have described so far: nodes that are far away from each other in the graph may never be able to efficiently transfer information to one another, even if we apply message passing several times.</p>
</blockquote>
<ul>
<li><strong>master node</strong>: this node is connected to all other nodes and edges in the network, and can act as a bridge between them to pass information, represented as U.</li>
</ul>
<h4 id="Graph-Nets-Layer"><a href="#Graph-Nets-Layer" class="headerlink" title="Graph Nets Layer"></a>Graph Nets Layer</h4><ul>
<li>这里，三种attribute都实现了更新</li>
</ul>
<p><img src="/images/blogs/GNN-Graph-Neural-Networks/image-20230810153359586.png" alt="image-20230810153359586"></p>
]]></content>
      <categories>
        <category>沐神开组会</category>
      </categories>
      <tags>
        <tag>李沐</tag>
        <tag>GNN</tag>
      </tags>
  </entry>
</search>
